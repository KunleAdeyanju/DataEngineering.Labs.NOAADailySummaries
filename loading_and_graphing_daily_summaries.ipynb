{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from my_json_helper import read_all_json_files_to_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading ./data/daily_summaries/.gitkeep: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>datatype</th>\n",
       "      <th>station</th>\n",
       "      <th>attributes</th>\n",
       "      <th>value</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-23T00:00:00</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>GHCND:US1DENC0002</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>58</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-23T00:00:00</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>GHCND:US1DENC0002</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>0</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-23T00:00:00</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>GHCND:US1DENC0002</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>0</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-23T00:00:00</td>\n",
       "      <td>WESD</td>\n",
       "      <td>GHCND:US1DENC0002</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>0</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-23T00:00:00</td>\n",
       "      <td>WESF</td>\n",
       "      <td>GHCND:US1DENC0002</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>0</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>2018-01-22T00:00:00</td>\n",
       "      <td>WDF2</td>\n",
       "      <td>GHCND:USW00013781</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>150</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_0.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2018-01-22T00:00:00</td>\n",
       "      <td>WDF5</td>\n",
       "      <td>GHCND:USW00013781</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>160</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_0.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>2018-01-22T00:00:00</td>\n",
       "      <td>WSF2</td>\n",
       "      <td>GHCND:USW00013781</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>54</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_0.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>2018-01-22T00:00:00</td>\n",
       "      <td>WSF5</td>\n",
       "      <td>GHCND:USW00013781</td>\n",
       "      <td>,,W,</td>\n",
       "      <td>63</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_0.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>2018-01-23T00:00:00</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>GHCND:US1DENC0001</td>\n",
       "      <td>,,N,0700</td>\n",
       "      <td>76</td>\n",
       "      <td>daily_summaries_FIPS10003_jan_2018_0.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1386 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date datatype            station attributes  value  \\\n",
       "0     2018-01-23T00:00:00     PRCP  GHCND:US1DENC0002   ,,N,0700     58   \n",
       "1     2018-01-23T00:00:00     SNOW  GHCND:US1DENC0002   ,,N,0700      0   \n",
       "2     2018-01-23T00:00:00     SNWD  GHCND:US1DENC0002   ,,N,0700      0   \n",
       "3     2018-01-23T00:00:00     WESD  GHCND:US1DENC0002   ,,N,0700      0   \n",
       "4     2018-01-23T00:00:00     WESF  GHCND:US1DENC0002   ,,N,0700      0   \n",
       "...                   ...      ...                ...        ...    ...   \n",
       "1381  2018-01-22T00:00:00     WDF2  GHCND:USW00013781       ,,W,    150   \n",
       "1382  2018-01-22T00:00:00     WDF5  GHCND:USW00013781       ,,W,    160   \n",
       "1383  2018-01-22T00:00:00     WSF2  GHCND:USW00013781       ,,W,     54   \n",
       "1384  2018-01-22T00:00:00     WSF5  GHCND:USW00013781       ,,W,     63   \n",
       "1385  2018-01-23T00:00:00     PRCP  GHCND:US1DENC0001   ,,N,0700     76   \n",
       "\n",
       "                                         source  \n",
       "0     daily_summaries_FIPS10003_jan_2018_1.json  \n",
       "1     daily_summaries_FIPS10003_jan_2018_1.json  \n",
       "2     daily_summaries_FIPS10003_jan_2018_1.json  \n",
       "3     daily_summaries_FIPS10003_jan_2018_1.json  \n",
       "4     daily_summaries_FIPS10003_jan_2018_1.json  \n",
       "...                                         ...  \n",
       "1381  daily_summaries_FIPS10003_jan_2018_0.json  \n",
       "1382  daily_summaries_FIPS10003_jan_2018_0.json  \n",
       "1383  daily_summaries_FIPS10003_jan_2018_0.json  \n",
       "1384  daily_summaries_FIPS10003_jan_2018_0.json  \n",
       "1385  daily_summaries_FIPS10003_jan_2018_0.json  \n",
       "\n",
       "[1386 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use json_helper to load all json objects into a dataframe called df_daily_summaries\n",
    "dir_path = os.path.join('./', 'data', 'daily_summaries')\n",
    "summaries_df = read_all_json_files_to_dataframe(dir_path)\n",
    "summaries_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1386, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display a summary of df_daily_summaries\n",
    "summaries_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many stations are there in total for FIPS10003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns the number of unique stations in the dataframe\n",
    "# summaries_df['station'].unique() -- creates a list of unique stations\n",
    "summaries_df['station'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame called temps_max that only contains the entries from df_daily_summaries where the datatype column is equal to TMAX. This DataFrame should only retain the date column and the value column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>max_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-01-23T00:00:00</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2018-01-24T00:00:00</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2018-01-25T00:00:00</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2018-01-26T00:00:00</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2018-01-27T00:00:00</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2018-01-28T00:00:00</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2018-01-29T00:00:00</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2018-01-30T00:00:00</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2018-01-31T00:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2018-01-01T00:00:00</td>\n",
       "      <td>-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2018-01-02T00:00:00</td>\n",
       "      <td>-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>2018-01-03T00:00:00</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2018-01-04T00:00:00</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2018-01-05T00:00:00</td>\n",
       "      <td>-82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2018-01-06T00:00:00</td>\n",
       "      <td>-88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>2018-01-07T00:00:00</td>\n",
       "      <td>-71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>2018-01-08T00:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>2018-01-09T00:00:00</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>2018-01-10T00:00:00</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>2018-01-11T00:00:00</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>2018-01-12T00:00:00</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>2018-01-13T00:00:00</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2018-01-14T00:00:00</td>\n",
       "      <td>-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>2018-01-15T00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>2018-01-16T00:00:00</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>2018-01-17T00:00:00</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>2018-01-18T00:00:00</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2018-01-19T00:00:00</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>2018-01-20T00:00:00</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>2018-01-21T00:00:00</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>2018-01-22T00:00:00</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  max_temp\n",
       "33    2018-01-23T00:00:00       172\n",
       "76    2018-01-24T00:00:00        72\n",
       "119   2018-01-25T00:00:00        28\n",
       "163   2018-01-26T00:00:00        39\n",
       "206   2018-01-27T00:00:00       150\n",
       "242   2018-01-28T00:00:00       133\n",
       "291   2018-01-29T00:00:00        78\n",
       "334   2018-01-30T00:00:00        39\n",
       "380   2018-01-31T00:00:00         6\n",
       "428   2018-01-01T00:00:00       -60\n",
       "475   2018-01-02T00:00:00       -38\n",
       "524   2018-01-03T00:00:00        -5\n",
       "579   2018-01-04T00:00:00       -21\n",
       "626   2018-01-05T00:00:00       -82\n",
       "665   2018-01-06T00:00:00       -88\n",
       "708   2018-01-07T00:00:00       -71\n",
       "751   2018-01-08T00:00:00         6\n",
       "785   2018-01-09T00:00:00        78\n",
       "829   2018-01-10T00:00:00        56\n",
       "874   2018-01-11T00:00:00       133\n",
       "915   2018-01-12T00:00:00       167\n",
       "963   2018-01-13T00:00:00       139\n",
       "1007  2018-01-14T00:00:00       -32\n",
       "1056  2018-01-15T00:00:00         0\n",
       "1106  2018-01-16T00:00:00        56\n",
       "1159  2018-01-17T00:00:00        22\n",
       "1205  2018-01-18T00:00:00        22\n",
       "1250  2018-01-19T00:00:00        83\n",
       "1294  2018-01-20T00:00:00       139\n",
       "1341  2018-01-21T00:00:00       117\n",
       "1379  2018-01-22T00:00:00       156"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataframe with only the TMAX data\n",
    "temps_max = summaries_df[summaries_df['datatype'] == 'TMAX']\n",
    "temps_max = temps_max.rename(columns={'value': 'max_temp'})\n",
    "columns_to_drop = ['station', 'attributes', 'source', 'datatype']\n",
    "temps_max.drop(columns=columns_to_drop, inplace=True) # inplace=True modifies the original dataframe, not creating a copy\n",
    "temps_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many entries are there in the temps_max DataFrame? What are the mean, min, and max values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's graph this DataFrame so we can get a visual representation for this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = temps_max['date'].str[8:10]\n",
    "y = temps_max['value'] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 10)\n",
    "ax.plot(x, y)\n",
    "ax.grid()\n",
    "ax.set(xlabel='day of month', ylabel='temperature in celsius', title='Max Temperatues Jan 2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame called temps_min that only contains the entries from df_daily_summaries where the datatype column is equal to TMIN. This DataFrame should only retain the date column and the value column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many entries are there in the temps_min DataFrame? What are the mean, min, and max values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the temps_min DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot both of these lines in the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(20, 10)\n",
    "ax.plot(x, temps_max['value'] / 10, color='red')\n",
    "ax.plot(x, temps_min['value'] / 10, color='blue')\n",
    "ax.grid()\n",
    "ax.set(xlabel='day of month', ylabel='temperature in celsius', title='Min & Max Temperatues Jan 2018')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
